# yolo v5-liteå­¦ä¹ è®°å½•

**å‰è¨€**

é€‰ç”¨liteæ¨¡å‹çš„åŸå› æ˜¯ä¸ºäº†é€‚åˆæ ‘è“æ´¾5ï¼ˆCortex-A76ï¼‰ç¡¬ä»¶æ€§èƒ½çš„æœ¬åœ°éƒ¨ç½²é€‰æ‹©çš„[ç½‘ç»œæ¨¡å‹](https://so.csdn.net/so/search?q=ç½‘ç»œæ¨¡å‹&spm=1001.2101.3001.7020)ä¸º **YOLOv5** æ¨¡å‹çš„å˜ç§ **YOLOv5-Lite** æ¨¡å‹ã€‚**YOLOv5-Lite** ä¸ **YOLOv5** ç›¸æ¯”è™½ç„¶ç‰ºç‰²äº†éƒ¨åˆ†ç½‘ç»œæ¨¡å‹ç²¾åº¦ï¼Œä½†æ˜¯ç¼ºæå¤§çš„æå‡äº†æ¨¡å‹çš„***\*æ¨ç†é€Ÿåº¦\****ï¼Œè¯¥æ¨¡å‹å±æ€§å°†æ›´é€‚åˆå®æˆ˜éƒ¨ç½²ä½¿ç”¨ã€‚åŒæ—¶ä¹Ÿç»™è®­ç»ƒè®¾å¤‡æ²¡æœ‰CUDAåŠ é€Ÿæä¾›ä¸€ä¸ªå‚æ•°å‚è€ƒ

**å‚è€ƒèµ„æ–™**

[GitHub - ppogg/YOLOv5-Lite: ğŸ…ğŸ…ğŸ…YOLOv5-Lite: Evolved from yolov5 and the size of model is only 900+kb (int8) and 1.7M (fp16). Reach 15 FPS on the Raspberry Pi 4B~](https://github.com/ppogg/YOLOv5-Lite)

[åŸºäºæ ‘è“æ´¾4Bçš„YOLOv5-Liteç›®æ ‡æ£€æµ‹çš„ç§»æ¤ä¸éƒ¨ç½²ï¼ˆå«è®­ç»ƒæ•™ç¨‹ï¼‰-CSDNåšå®¢](https://blog.csdn.net/black_sneak/article/details/131374492)



## 1ã€yolov5æ¦‚è¿°



## 2ã€è®­ç»ƒ

æ•°æ®é›†åˆ¶ä½œ
å¸¸è§„çš„ç¥ç»ç½‘ç»œæ¨¡å‹è®­ç»ƒæ˜¯éœ€è¦æ”¶é›†åˆ°å¤§é‡è¯­ä¹‰ä¸°å¯Œçš„æ•°æ®é›†è¿›è¡Œè®­ç»ƒçš„ã€‚ä½†æ˜¯è€ƒè™‘å®é™…å·¥ç¨‹ä¸‹å¯èƒ½ä»…éœ€è¦å¯¹å·²çŸ¥åœºåœ°ä¸”å›ºå®šå®ç‰©è¿›è¡Œç›®æ ‡æ£€æµ‹è¿½è¸ªç­‰ä»»åŠ¡ï¼Œè¿™ä¸ªæ—¶å€™æˆ‘ä»¬å¯ä»¥é‡‡å–å·æ‡’çš„ä¸‹æ–¹ä½œè€…ä½¿ç”¨çš„æ–¹æ³•ï¼

1ã€ä½¿ç”¨æ ‘è“æ´¾5çš„ Camera ç›´æ¥åœ¨æ•è·éœ€è¦è¯†åˆ«ç›®æ ‡ç‰©çš„å›¾ç‰‡ä¿¡æ¯ï¼ˆæ•è·æœŸé—´è½¬åŠ¨å¾…è¯†åˆ«çš„ç›®æ ‡ç‰©ä½“ï¼‰ï¼›

```python
import cv2
from threading import Thread
import uuid
import os
import time
count = 0
def image_collect(cap):
    global count
    while True:
        success, img = cap.read()
        if success:
            file_name = str(uuid.uuid4())+'.jpg'
            cv2.imwrite(os.path.join('images',file_name),img)
            count = count+1
            print("save %d %s"%(count,file_name))
        time.sleep(0.4)
 
if __name__ == "__main__":
    
    os.makedirs("images",exist_ok=True)
    
    # æ‰“å¼€æ‘„åƒå¤´
    cap = cv2.VideoCapture(0)
 
    m_thread = Thread(target=image_collect, args=([cap]),daemon=True)
    
    while True:
 
        # è¯»å–ä¸€å¸§å›¾åƒ
 
        success, img = cap.read()
 
        if not success:
 
            continue
 
        cv2.imshow("video",img)
 
        key =  cv2.waitKey(1) & 0xFF   
 
        # æŒ‰é”® "q" é€€å‡º
        if key ==  ord('c'):
            m_thread.start()
            continue
        elif key ==  ord('q'):
            break
 
    cap.release() 
```

æ²¡æœ‰æŒ‡æ˜åˆ†è¾¨ç‡ä¿¡æ¯é»˜è®¤ä½¿ç”¨æ‘„åƒå¤´æ”¯æŒçš„æœ€å¤§åˆ†è¾¨ç‡ï¼Œæ­¤å¤„é‡‡é›†åˆ†è¾¨ç‡ä¸º1280*960

æŒ‰åŠ¨ **â€œcâ€** å¼€å§‹é‡‡é›†å¾…è¯†åˆ«ç›®æ ‡å›¾åƒï¼ŒæŒ‰åŠ¨ **â€œqâ€** é€€å‡ºæ‘„åƒå¤´ **Camera** çš„å›¾ç‰‡é‡‡é›†ï¼›

### åœ¨é‡‡é›†å®Œæ¯•ä¹‹åä½¿ç”¨labelimgè¿›è¡Œæ ‡æ³¨

via canda to create python3.9 virtual labelimgï¼Œlastest python version have some unknown error

```
conda create -n labelimg python=3.10
conda init
conda activate labelimg
labelimg
```

 Open dir (select the source photo flie, usually the image flie)

Change Save Dir(select the save flie,usually the label flie)

next change PascalVOC mode to yolo mode

and now you can use 'w' create RectBox, 'd'  Next image

all well done the labels saved to 'label' flie

we can directly use it via code ,access the label flie

### train the model

first create the mydata.yaml ,we need points to your dataset

```
dataset/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ images/
â”‚   â””â”€â”€ labels/

```

and in this dataset only one class 'RED'

```
train: E:/onedrive/Desktop/YOLOv5-Lite-master/dataphoto/train
val: E:/onedrive/Desktop/YOLOv5-Lite-master/dataphoto/val
nc: 1
names: ['RED']
```

in train.py also need to change variable because this pc not support CUDA 

in line461 include mydata.yaml and the epochs(highly epochs means more training)

```
python train.py --data data/mydata.yaml --weights weights/v5Lite-s.pt --device cpu --epochs 100
```

Set default device in code if not specified:

```
parser.add_argument('--device', default='cpu', help='device to use, e.g. 0 or cpu')
```

